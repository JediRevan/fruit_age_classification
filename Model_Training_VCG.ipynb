{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 52/52 [03:37<00:00,  4.18s/it]\n",
      "Validating: 100%|██████████| 7/7 [00:14<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 8.8812, Val Loss: 6.6797\n",
      "Validation loss improved, saving model to checkpoint.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 52/52 [03:46<00:00,  4.36s/it]\n",
      "Validating: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 1.9719, Val Loss: 4.3443\n",
      "Validation loss improved, saving model to checkpoint.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 52/52 [03:56<00:00,  4.54s/it]\n",
      "Validating: 100%|██████████| 7/7 [00:11<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.9521, Val Loss: 5.4041\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 52/52 [04:39<00:00,  5.37s/it]\n",
      "Validating:  29%|██▊       | 2/7 [00:03<00:09,  2.00s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spectral.io.envi import open as envi_open\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "# --- Constants ---\n",
    "DATA_DIR = \"./VIS\"  # Update with your dataset path\n",
    "IMG_SIZE = 224  # Resize images to ResNet-compatible size\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def read_hyperspectral_image(hdr_file):\n",
    "    \"\"\"Load and preprocess hyperspectral image from .hdr and its associated .bin file.\"\"\"\n",
    "    bin_file = hdr_file.replace(\".hdr\", \".bin\")\n",
    "    try:\n",
    "        img = envi_open(hdr_file, image=bin_file).load()\n",
    "        img = np.mean(img, axis=2)\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img = transforms.Resize((IMG_SIZE, IMG_SIZE))(img)\n",
    "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading image: {hdr_file}\") from e\n",
    "\n",
    "def get_image_metadata(file_name):\n",
    "    parts = file_name.split(\"_\")\n",
    "    day = int(parts[2])  # Extract day (e.g., 'day_10' -> 10)\n",
    "    mango_id = parts[4].split(\".\")[0]\n",
    "    return mango_id, day\n",
    "\n",
    "def create_pairs(data):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for mango_id, group in data.groupby(\"mango_id\"):\n",
    "        group = group.sort_values(\"day\")\n",
    "        files = group[\"file\"].tolist()\n",
    "        days = group[\"day\"].tolist()\n",
    "        for i in range(len(files) - 1):\n",
    "            for j in range(i + 1, len(files)):\n",
    "                if days[i] != days[j]:\n",
    "                    pairs.append((files[i], files[j]))\n",
    "                    labels.append(abs(days[j] - days[i]))\n",
    "    return pairs, labels\n",
    "\n",
    "def validate_pairs_and_labels(pairs, labels):\n",
    "    valid_pairs = []\n",
    "    valid_labels = []\n",
    "    for i, (file1, file2) in enumerate(pairs):\n",
    "        hdr1, hdr2 = file1.replace(\".bin\", \".hdr\"), file2.replace(\".bin\", \".hdr\")\n",
    "        bin1, bin2 = hdr1.replace(\".hdr\", \".bin\"), hdr2.replace(\".hdr\", \".bin\")\n",
    "        if os.path.exists(hdr1) and os.path.exists(hdr2) and os.path.exists(bin1) and os.path.exists(bin2):\n",
    "            valid_pairs.append((file1, file2))\n",
    "            valid_labels.append(labels[i])\n",
    "    return valid_pairs, valid_labels\n",
    "\n",
    "# --- Data Preparation ---\n",
    "data = []\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".bin\"):\n",
    "            try:\n",
    "                mango_id, day = get_image_metadata(file)\n",
    "                hdr_file = os.path.join(root, file.replace(\".bin\", \".hdr\"))\n",
    "                if os.path.exists(hdr_file):\n",
    "                    data.append({\n",
    "                        \"file\": os.path.join(root, file),\n",
    "                        \"hdr\": hdr_file,\n",
    "                        \"mango_id\": mango_id,\n",
    "                        \"day\": day\n",
    "                    })\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "train_ids, test_ids = train_test_split(data[\"mango_id\"].unique(), test_size=0.2, random_state=42)\n",
    "val_ids, test_ids = train_test_split(test_ids, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = data[data[\"mango_id\"].isin(train_ids)]\n",
    "val_data = data[data[\"mango_id\"].isin(val_ids)]\n",
    "test_data = data[data[\"mango_id\"].isin(test_ids)]\n",
    "\n",
    "train_pairs, train_labels = create_pairs(train_data)\n",
    "val_pairs, val_labels = create_pairs(val_data)\n",
    "test_pairs, test_labels = create_pairs(test_data)\n",
    "\n",
    "train_pairs, train_labels = validate_pairs_and_labels(train_pairs, train_labels)\n",
    "val_pairs, val_labels = validate_pairs_and_labels(val_pairs, val_labels)\n",
    "test_pairs, test_labels = validate_pairs_and_labels(test_pairs, test_labels)\n",
    "\n",
    "# --- PyTorch Dataset ---\n",
    "class MangoPairDataset(Dataset):\n",
    "    def __init__(self, pairs, labels):\n",
    "        self.pairs = pairs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file1, file2 = self.pairs[idx]\n",
    "        hdr1 = file1.replace(\".bin\", \".hdr\")\n",
    "        hdr2 = file2.replace(\".bin\", \".hdr\")\n",
    "        img1 = read_hyperspectral_image(hdr1)\n",
    "        img2 = read_hyperspectral_image(hdr2)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return img1, img2, label\n",
    "\n",
    "train_dataset = MangoPairDataset(train_pairs, train_labels)\n",
    "val_dataset = MangoPairDataset(val_pairs, val_labels)\n",
    "test_dataset = MangoPairDataset(test_pairs, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Vision Transformer Model ---\n",
    "class ViTRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTRegression, self).__init__()\n",
    "        self.base_model = vit_b_16(weights=\"IMAGENET1K_V1\")\n",
    "        in_features = self.base_model.heads[0].in_features\n",
    "        self.base_model.heads = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        x1 = self.base_model(img1)\n",
    "        x2 = self.base_model(img2)\n",
    "        diff = torch.abs(x1 - x2)\n",
    "        return diff\n",
    "\n",
    "model = ViTRegression().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- Early Stopping ---\n",
    "class EarlyStopping:\n",
    "    \"\"\"Stop training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=5, delta=0, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model, path='checkpoint.pth'):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved, saving model to {path}.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train_model_with_early_stopping(model, train_loader, val_loader, epochs, patience):\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for img1, img2, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img1, img2).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for img1, img2, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "                img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(img1, img2).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pth'))\n",
    "    return model\n",
    "\n",
    "# Train the model with early stopping\n",
    "train_model_with_early_stopping(model, train_loader, val_loader, EPOCHS, patience=5)\n",
    "\n",
    "# --- Testing ---\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in test_loader:\n",
    "            img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(img1, img2).squeeze()\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20:   0%|          | 0/156 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Training Epoch 1/20: 100%|██████████| 156/156 [02:04<00:00,  1.25it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.0003, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 156/156 [02:23<00:00,  1.09it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 156/156 [02:29<00:00,  1.05it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 156/156 [02:30<00:00,  1.04it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 156/156 [02:31<00:00,  1.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 156/156 [02:34<00:00,  1.01it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 156/156 [02:31<00:00,  1.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 156/156 [02:30<00:00,  1.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 156/156 [02:32<00:00,  1.02it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 156/156 [02:33<00:00,  1.01it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 156/156 [02:30<00:00,  1.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 156/156 [02:31<00:00,  1.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 156/156 [02:27<00:00,  1.06it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 156/156 [02:28<00:00,  1.05it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 156/156 [02:28<00:00,  1.05it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 156/156 [02:28<00:00,  1.05it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 156/156 [02:27<00:00,  1.06it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 156/156 [02:29<00:00,  1.04it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 156/156 [02:30<00:00,  1.03it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 156/156 [02:27<00:00,  1.06it/s]\n",
      "Validating: 100%|██████████| 3/3 [00:00<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Loss: 0.0000, Val Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spectral.io.envi import open as envi_open\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "# --- Constants ---\n",
    "DATA_DIR = \"./VIS\"  # Update with your dataset path\n",
    "IMG_SIZE = 224  # Resize images to ResNet-compatible size\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def read_hyperspectral_image(hdr_file):\n",
    "    \"\"\"Load and preprocess hyperspectral image from .hdr and its associated .bin file.\"\"\"\n",
    "    bin_file = hdr_file.replace(\".hdr\", \".bin\")  # Ensure .bin file path\n",
    "    try:\n",
    "        img = envi_open(hdr_file, image=bin_file).load()  # Explicitly link .bin file\n",
    "        img = np.mean(img, axis=2)  # Collapse bands to single channel\n",
    "        img = np.stack([img] * 3, axis=-1)  # Convert grayscale to 3 channels\n",
    "        img = transforms.ToTensor()(img)\n",
    "        img = transforms.Resize((IMG_SIZE, IMG_SIZE))(img)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error reading image: {hdr_file}\") from e\n",
    "\n",
    "def get_image_metadata(file_path):\n",
    "    \"\"\"Parse file path to extract mango ID and day.\"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    parts = file_name.split(\"_\")\n",
    "    if len(parts) < 6 or parts[1] != \"day\":\n",
    "        raise ValueError(f\"Unexpected file naming format: {file_name}\")\n",
    "    day = int(parts[2])  # Extract day\n",
    "    mango_id = \"_\".join(parts[:4])  # Unique mango ID\n",
    "    return mango_id, day\n",
    "\n",
    "def create_pairs(data):\n",
    "    \"\"\"Generate all possible pairs of images with their day differences.\"\"\"\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for mango_id, group in data.groupby(\"mango_id\"):\n",
    "        files = group[\"file\"].tolist()\n",
    "        days = group[\"day\"].tolist()\n",
    "        for (file1, day1), (file2, day2) in combinations(zip(files, days), 2):\n",
    "            pairs.append((file1, file2))\n",
    "            labels.append(abs(day1 - day2))\n",
    "    return pairs, labels\n",
    "\n",
    "def validate_pairs_and_labels(pairs, labels):\n",
    "    \"\"\"Validate pairs and corresponding labels.\"\"\"\n",
    "    valid_pairs = []\n",
    "    valid_labels = []\n",
    "    for i, (file1, file2) in enumerate(pairs):\n",
    "        hdr1, hdr2 = file1.replace(\".bin\", \".hdr\"), file2.replace(\".bin\", \".hdr\")\n",
    "        bin1, bin2 = hdr1.replace(\".hdr\", \".bin\"), hdr2.replace(\".hdr\", \".bin\")\n",
    "        if os.path.exists(hdr1) and os.path.exists(hdr2) and os.path.exists(bin1) and os.path.exists(bin2):\n",
    "            valid_pairs.append((file1, file2))\n",
    "            valid_labels.append(labels[i])\n",
    "    return valid_pairs, valid_labels\n",
    "\n",
    "# --- Data Preparation ---\n",
    "def assign_split(file_name):\n",
    "    \"\"\"Assign a split category based on the 'y' value in the file name.\"\"\"\n",
    "    parts = file_name.split(\"_\")\n",
    "    if len(parts) < 6:\n",
    "        raise ValueError(f\"Unexpected file naming format: {file_name}\")\n",
    "    y_value = int(parts[4])  # Extract the `y` value\n",
    "    if 1 <= y_value <= 32:\n",
    "        return \"train\"\n",
    "    elif 33 <= y_value <= 36:\n",
    "        return \"val\"\n",
    "    elif 37 <= y_value <= 40:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected y value: {y_value} in file name: {file_name}\")\n",
    "\n",
    "data = []\n",
    "for root, _, files in os.walk(DATA_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".bin\"):\n",
    "            bin_file = os.path.join(root, file)\n",
    "            hdr_file = os.path.join(root, file.replace(\".bin\", \".hdr\"))\n",
    "            if not os.path.exists(hdr_file):\n",
    "                continue\n",
    "            try:\n",
    "                mango_id, day = get_image_metadata(file)\n",
    "                split = assign_split(file)  # Assign split based on 'y'\n",
    "                data.append({\"file\": bin_file, \"hdr\": hdr_file, \"mango_id\": mango_id, \"day\": day, \"split\": split})\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Split data based on the 'split' column\n",
    "train_data = data[data[\"split\"] == \"train\"]\n",
    "val_data = data[data[\"split\"] == \"val\"]\n",
    "test_data = data[data[\"split\"] == \"test\"]\n",
    "\n",
    "# Create pairs and labels\n",
    "train_pairs, train_labels = create_pairs(train_data)\n",
    "val_pairs, val_labels = create_pairs(val_data)\n",
    "test_pairs, test_labels = create_pairs(test_data)\n",
    "\n",
    "# Validate pairs\n",
    "train_pairs, train_labels = validate_pairs_and_labels(train_pairs, train_labels)\n",
    "val_pairs, val_labels = validate_pairs_and_labels(val_pairs, val_labels)\n",
    "test_pairs, test_labels = validate_pairs_and_labels(test_pairs, test_labels)\n",
    "\n",
    "# --- PyTorch Dataset ---\n",
    "class MangoPairDataset(Dataset):\n",
    "    def __init__(self, pairs, labels):\n",
    "        self.pairs = pairs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file1, file2 = self.pairs[idx]\n",
    "        hdr1 = file1.replace(\".bin\", \".hdr\")\n",
    "        hdr2 = file2.replace(\".bin\", \".hdr\")\n",
    "        img1 = read_hyperspectral_image(hdr1)\n",
    "        img2 = read_hyperspectral_image(hdr2)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return img1, img2, label\n",
    "\n",
    "train_dataset = MangoPairDataset(train_pairs, train_labels)\n",
    "val_dataset = MangoPairDataset(val_pairs, val_labels)\n",
    "test_dataset = MangoPairDataset(test_pairs, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- ResNet-50 Model ---\n",
    "class ViTRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViTRegression, self).__init__()\n",
    "        self.base_model = vit_b_16(weights=\"IMAGENET1K_V1\")\n",
    "        \n",
    "        # Extract the in_features of the current head\n",
    "        in_features = self.base_model.heads[0].in_features\n",
    "        \n",
    "        # Replace the head with a single linear layer for regression\n",
    "        self.base_model.heads = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        x1 = self.base_model(img1)\n",
    "        x2 = self.base_model(img2)\n",
    "        diff = torch.abs(x1 - x2)\n",
    "        return diff\n",
    "\n",
    "model = ViTRegression().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train_model(model, train_loader, val_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for img1, img2, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img1, img2).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for img1, img2, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "                img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(img1, img2).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, EPOCHS)\n",
    "\n",
    "\n",
    "# --- Testing ---\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(img1, img2).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# --- Save Model ---\n",
    "torch.save(model.state_dict(), \"resnet50_mango_time_diff.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_regression_metrics(model, data_loader):\n",
    "    \"\"\"Evaluate regression metrics for a given data loader.\"\"\"\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, labels in tqdm(data_loader, desc=\"Evaluating Metrics\"):\n",
    "            img1, img2, labels = img1.to(DEVICE), img2.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(img1, img2).squeeze()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    print(all_labels)\n",
    "    print(all_predictions)\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(all_labels, all_predictions)\n",
    "    mse = mean_squared_error(all_labels, all_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(all_labels, all_predictions)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"R^2 Score: {r2:.4f}\")\n",
    "\n",
    "    return mae, mse, rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2491"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(val_dataset\u001b[38;5;241m.\u001b[39mpairs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "len(val_dataset.pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
